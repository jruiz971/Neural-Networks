{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm\n",
    "Normalizar para tener desviacion estandar de 1 y media de 0 después de cada capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no sabemos cuál es la media o std de la capa k, entonces usamos la media y la std de cada batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media y std son vectores con el mismo número de canales que $x$. Cada canal puede tener diferente media y desviación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Pero no vamos a poder predecir cosas con diferente media o std!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces $Batchnorm$ decide independiemtemete otros dos parámetros, uno multiplicativo $\\gamma$ y otro aditivo $\\beta$ con el mismo número de canales que $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicilizamos como\n",
    "- $\\gamma$ vector de unos \n",
    "- $\\beta$ vector de ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nn.BatchNorm1d( 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d para vectores (no para imágenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6935, -0.9846, -1.5932,  ..., -0.8760, -1.0148, -0.5973],\n",
       "        [-0.8761,  0.9017,  0.6878,  ..., -0.6489, -0.9991,  0.0985],\n",
       "        [ 0.8077, -0.2551, -0.8767,  ..., -0.8424, -0.0745, -0.8043],\n",
       "        ...,\n",
       "        [ 0.9356,  1.5005,  0.7621,  ...,  0.1580, -0.1781,  0.3653],\n",
       "        [ 0.7895,  0.0960,  0.7687,  ..., -0.8140, -0.7490, -1.3115],\n",
       "        [-1.2950,  0.9852, -0.0650,  ..., -1.0802,  1.0070, -1.3761]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand( 64, 20 )\n",
    "#batch_size 64 y de tamaño 20\n",
    "B(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma$ y $\\beta$ requieren gardiente porque después de entrenar la red ya van a cambiar sus valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo ponemos Batchnorm dentro de nuestra red?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(nn.BatchNorm2d( 3 ), #Es ideal empezar normalizando los datos, además nos evitamos un paso anterior de normalizar\n",
    "              nn.Conv2d( 3, 16, kernel_size = 3 ), \n",
    "              nn.ReLU(),\n",
    "              nn.BatchNorm2d( 16 ), # Con el tamaño que sale de la transformación lineal\n",
    "              nn.Conv2d( 16, 32, kernel_size = 3 ),\n",
    "              nn.ReLU(),\n",
    "              nn.BatchNorm2d( 32 )              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresa la estructura de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con Batchnorm aumentamos muchísimo la accuracy de nuestros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
