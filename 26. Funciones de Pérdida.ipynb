{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import fastai.vision.all as fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando clasificamos aves lo que nos interesa es maximizar la accuracy (minimizar la taza de error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "No es buena idea maximizarla directamente, pues sólo se fija en el máximo y deja todo lo demás. Tampoco es continua. \n",
    "\n",
    "Dice si la imagen es o no es. Entonces debemos maximizar otra función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder, img_size,batch_size):\n",
    "    tmfs = fv.aug_transforms(flip_vert=False,\n",
    "                            max_rotate=10,\n",
    "                            max_lighting=0.25,\n",
    "                            max_zoom=1.2,\n",
    "                            max_warp=0.2)\n",
    "    data = fv.DataBlock(blocks  = (fv.ImageBlock, fv.CategoryBlock),\n",
    "                        get_items = fv.get_image_files,\n",
    "                        get_y     = fv.parent_label, #Como a partir de la imagen encpontarr la categoria\n",
    "                        splitter  = fv.GrandparentSplitter(), #si el abyelo es train o test\n",
    "                        item_tfms = fv.Resize(img_size),#transformcaiones antes de juntar en batch y despues de juntar en batch)\n",
    "                        batch_tfms = tmfs)\n",
    "    return data.dataloaders(folder, bs=batch_size)#Agarra las imagenes y las regresa en batches\n",
    "\n",
    "birds = load_data(\"/storage/birds\", img_size=128, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Flatten es una capa que ayuda a pasar de la parte convolucional a la parte lineal\n",
    "\n",
    "#Lo que hace la clase es que le pasamos algo y nos regresa eso mismo pero sin los 1\n",
    "class Flatten(nn.Module):   #Creamos un módulo que hereda de nn.Module\n",
    "    def __init__(self):    #Para crear un objeto\n",
    "        super().__init__() #Le decimos a nn.Module que se inicie\n",
    "    \n",
    "    def forward( self, x ): #\n",
    "        #return x.squeeze()\n",
    "        return x.reshape (x.shape[0],-1) #Toma la primera y adivina el resto\n",
    "        #Se agrega esta porque si el batch es de tam 1, squezze lo elimina\n",
    "\n",
    "lx97  = nn.Sequential( #Sequential para cosas sencillas\n",
    "    nn.BatchNorm2d( 3 ), #Ideal comenzar normalizando \n",
    "    #Convolucion de entrada 3, de 32 filtros, de tamaño 3x3, \n",
    "    #sride -> ¿cuánto brinca?, padding -> pone el brde negro para no perder pixeles\n",
    "    nn.Conv2d( 3, 32, kernel_size = 3, stride = 2, padding = 1),\n",
    "    \n",
    "    #Acivacion\n",
    "    nn.ReLU(),\n",
    "    ##ResBlock( crear_residual( 16 ) ),\n",
    "    #Reducir el tamaño de a  imagen (será más rápido)\n",
    "    #Cada cuadro de 2x2 agarra el más grande.\n",
    "    #Reduce a la mitad\n",
    "    #nn.MaxPool2d(2),\n",
    "    #nn.Conv2d( 16, 32, kernel_size=2 ),\n",
    "    #nn.ReLU(),\n",
    "    nn.BatchNorm2d( 32 ),\n",
    "    nn.Conv2d( 32, 32, kernel_size=2, stride = 1, padding = 1 ),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d( 32 ),\n",
    "    \n",
    "    #Empezamos en la cantidad de filtros con los que acabamos en Conv2d anterior\n",
    "    nn.Conv2d( 32, 64, kernel_size = 2, stride = 1, padding = 1),\n",
    "    \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d( 64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d( 128 ),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d( 128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.BatchNorm2d( 256 ),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d( 256, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.BatchNorm2d( 256 ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d( 256, 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.BatchNorm2d( 512 ),\n",
    "    nn.ReLU(),\n",
    "    #--Aquí acabamos con la parte convolucional--#\n",
    "    \n",
    "    #--Llegamos a la parte lineal--#\n",
    "    \n",
    "    nn.AdaptiveAvgPool2d(1), #Reducir el tamaño a 1x1xn_canales\n",
    "    #Podemos usar diferentes métodos para llegar a 1x1\n",
    "    Flatten(), #Usamos la funcion que habiamos creado pra eliminar las de dim 1\n",
    "    #Los quita para poder usar Linear\n",
    "    nn.Linear( 512, 256), #Completamente conectada\n",
    "    nn.ReLU(),\n",
    "    nn.Linear( 256, birds.c) #salida con el total de clases de los datos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = birds.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorCategory([170, 145,  72, 170,  46,  74,  14,  62, 157,  57,   0,  14,  25, 100,\n",
       "          66,  40,  36, 101,   9,   1,  78,  97, 159, 139,  36,  23,  80,  86,\n",
       "         169,  98, 126,  11,  73, 188,  21, 129, 179, 172,  72, 135,  64, 123,\n",
       "          55,  41, 185, 185, 133, 181,   4, 100,  22, 150, 150, 124,  88, 109,\n",
       "         186, 142, 198, 125, 107,  77, 184,  78], device='cuda:0'),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x -> batch de imágenes\n",
    "y -> Tensor de números enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para clasificar.\n",
    "Maximiza la probabilidad de clasificar correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le debemos pasar yp y y sin softmax y sin one-hot-encodear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
